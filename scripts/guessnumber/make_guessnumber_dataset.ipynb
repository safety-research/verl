{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/n/home12/cfpark00/anaconda3/envs/vllm/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datasets\n",
    "import argparse\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_dir = '../../data/datasets/guessnumber'\n",
    "os.makedirs(local_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 169.84ba/s]\n",
      "Creating json from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 13.74ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "90426"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#no train test, its all the same\n",
    "data_source = 'cfpark00/guessnumber'\n",
    "max_num=128\n",
    "split=str(max_num)\n",
    "max_turns=16\n",
    "###\n",
    "system_prompt=(\n",
    "    f\"The user will think of a number between 1 and {max_num}. \"\n",
    "    \"Your mission is to find this number as quickly as possible. \"\n",
    "    \"On each turn, you propose a number and the user will tell you \"\n",
    "    \"\\\"Higher!\\\" if the number is higher than your guess, \"\n",
    "    \"\\\"Lower!\\\" if the number is lower than your guess, or \"\n",
    "    \"\\\"Correct!\\\" if the number is correct.\\n\"\n",
    "    \"Response Format:\\n\"\n",
    "    \"Reasoning: {reasoning (string)}\\n\"\n",
    "    \"Proposition: {guess (integer)}\"\n",
    ")\n",
    "data=[]\n",
    "for idx,number in enumerate(range(1,max_num+1)):\n",
    "    messages=[\n",
    "        {\"role\":\"system\",\"content\":system_prompt},\n",
    "        {\"role\":\"user\",\"content\":f\"Okay, I'm ready, I have a number between 1 and {max_num} in mind.\"},\n",
    "    ]\n",
    "    hidden_params={\n",
    "        \"number\":number,\n",
    "        \"max_turns\":max_turns,\n",
    "        \"max_num\":max_num\n",
    "    }\n",
    "    datum={\n",
    "        \"data_source\":data_source,\n",
    "        \"prompt\":messages,\n",
    "        \"hidden_params\":hidden_params,\n",
    "        \"reward_model\":{\n",
    "            \"style\":\"rule\",\n",
    "            \"ground_truth\":number\n",
    "        },\n",
    "        \"extra_info\": {\n",
    "            \"index\": idx\n",
    "        }\n",
    "    }\n",
    "    data.append(datum)\n",
    "ds=datasets.Dataset.from_list(data)\n",
    "ds.to_parquet(os.path.join(local_dir,f\"{split}.parquet\"))\n",
    "ds.to_json(os.path.join(local_dir,f\"{split}.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "moddel=transformers.AutoModelForCausalLM.from_pretrained('Qwen/Qwen2.5-0.5B-Instruct',torch_dtype=torch.bfloat16,device_map=\"auto\")\n",
    "tokenizer=transformers.AutoTokenizer.from_pretrained('Qwen/Qwen2.5-0.5B-Instruct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|im_start|>system\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\\n<|im_start|>user\\nHigher!<|im_end|>\\n<|im_start|>assistant\\nI\\'m sorry, but I am Qwen, an AI language model. I don\\'t have feelings or emotions like humans do, so I can\\'t \"feel\" higher than I do. My purpose is to assist you with information and provide helpful responses. If there\\'s anything specific you need help with, feel free to ask!<|im_end|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>',\n",
       " '<|im_start|>system\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\\n<|im_start|>user\\nHigher!<|im_end|>\\n<|im_start|>assistant\\nI\\'m not sure what you\\'re asking for \"higher.\" Could you please provide more context or clarify your question? Different people might have different definitions of \"higher\" in various contexts. If you meant something else entirely, I\\'d be happy to try and help further if you can give me some more information about what you\\'re looking for or need assistance with.<|im_end|>']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids=tokenizer.apply_chat_template([{\"role\":\"user\",\"content\":\"Higher!\"}],tokenize=True,add_generation_prompt=True,return_tensors='pt')\n",
    "gen=moddel.generate(input_ids.to(moddel.device),max_length=128,temperature=1.0,num_return_sequences=2)\n",
    "gen_text=tokenizer.batch_decode(gen,skip_special_tokens=False)\n",
    "gen_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<|endoftext|>', '<|im_end|>')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.pad_token_id),tokenizer.decode(tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0]),\n",
       " tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True, False, False]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m=(torch.tensor([0, 0, 2, 42, 3, 5, 1, 0, 3, 4, 2, 1, 0, 0])==1).long()\n",
    "mm=torch.cumsum(torch.flip(m,dims=(0,)),dim=0).bool().flip(dims=(0,))\n",
    "m,mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 31])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.apply_chat_template([{\"role\":\"user\",\"content\":\"Higher!\"}],tokenize=True,add_generation_prompt=True,return_tensors='pt').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('<|im_start|>', 151644), ('system', 8948), ('\\n', 198), ('You', 2610), (' are', 525), (' Q', 1207), ('wen', 16948), (',', 11), (' created', 3465), (' by', 553), (' Alibaba', 54364), (' Cloud', 14817), ('.', 13), (' You', 1446), (' are', 525), (' a', 264), (' helpful', 10950), (' assistant', 17847), ('.', 13), ('<|im_end|>', 151645), ('\\n', 198), ('<|im_start|>', 151644), ('user', 872), ('\\n', 198), ('Higher', 87445), ('!', 0), ('<|im_end|>', 151645), ('\\n', 198), ('<|im_start|>', 151644), ('assistant', 77091), ('\\n', 198)]\n"
     ]
    }
   ],
   "source": [
    "tids=tokenizer.apply_chat_template([{\"role\":\"user\",\"content\":\"Higher!\"}],tokenize=True,add_generation_prompt=True)\n",
    "print([(tokenizer.decode(tid),tid) for tid in tids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151643"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151645"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_assistant_tokens_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2TokenizerFast(name_or_path='Qwen/Qwen2.5-0.5B-Instruct', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t151643: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151644: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151645: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151646: AddedToken(\"<|object_ref_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151647: AddedToken(\"<|object_ref_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151648: AddedToken(\"<|box_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151649: AddedToken(\"<|box_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151650: AddedToken(\"<|quad_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151651: AddedToken(\"<|quad_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151652: AddedToken(\"<|vision_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151653: AddedToken(\"<|vision_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151654: AddedToken(\"<|vision_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151655: AddedToken(\"<|image_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151656: AddedToken(\"<|video_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151657: AddedToken(\"<tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151658: AddedToken(\"</tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151659: AddedToken(\"<|fim_prefix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151660: AddedToken(\"<|fim_middle|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151661: AddedToken(\"<|fim_suffix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151662: AddedToken(\"<|fim_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151663: AddedToken(\"<|repo_name|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "\t151664: AddedToken(\"<|file_sep|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([tid==151644 for tid in tids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [872], 'attention_mask': [1]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"user\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rl data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict={}\n",
    "splits=[\"train\",\"test\"]\n",
    "seeds=[0,42]\n",
    "n_gamess=[1_000,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_base_name=\"always1\"\n",
    "for split,seed,n_games in zip(splits,seeds,n_gamess):\n",
    "    np.random.seed(seed)\n",
    "    datas=[]\n",
    "    for _ in range(n_games):\n",
    "        box_names_three=[0,1,2]\n",
    "        box_name_correct=1\n",
    "        data={\n",
    "            \"prompt\":\"Make your choice: Box {b1} vs. Box {b2} vs. Box {b3}\".format(b1=box_names_three[0],b2=box_names_three[1],b3=box_names_three[2]),\n",
    "            \"choices\":box_names_three,\n",
    "            \"answer\": box_name_correct\n",
    "        }\n",
    "        datas.append(data)\n",
    "    split_name=split_base_name+\"_\"+split\n",
    "    data_dict[split_name]=datasets.Dataset.from_list(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_base_name=\"smallest\"\n",
    "box_names=np.arange(100)\n",
    "for split,seed,n_games in zip(splits,seeds,n_gamess):\n",
    "    np.random.seed(seed)\n",
    "    datas=[]\n",
    "    for _ in range(n_games):\n",
    "        box_names_three=np.random.choice(box_names,3,replace=False)\n",
    "        box_name_correct=np.min(box_names_three)\n",
    "        data={\n",
    "            \"prompt\":\"Make your choice: Box {b1} vs. Box {b2} vs. Box {b3}\".format(b1=box_names_three[0],b2=box_names_three[1],b3=box_names_three[2]),\n",
    "            \"choices\":box_names_three,\n",
    "            \"answer\": box_name_correct\n",
    "        }\n",
    "        datas.append(data)\n",
    "    split_name=split_base_name+\"_\"+split\n",
    "    data_dict[split_name]=datasets.Dataset.from_list(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_base_name=\"second\"\n",
    "box_names=np.arange(100)\n",
    "for split,seed,n_games in zip(splits,seeds,n_gamess):\n",
    "    np.random.seed(seed)\n",
    "    datas=[]\n",
    "    for _ in range(n_games):\n",
    "        box_names_three=np.random.choice(box_names,3,replace=False)\n",
    "        box_name_correct= box_names_three[1]\n",
    "        data={\n",
    "            \"prompt\":\"Make your choice: Box {b1} vs. Box {b2} vs. Box {b3}\".format(b1=box_names_three[0],b2=box_names_three[1],b3=box_names_three[2]),\n",
    "            \"choices\":box_names_three,\n",
    "            \"answer\": box_name_correct\n",
    "        }\n",
    "        datas.append(data)\n",
    "    split_name=split_base_name+\"_\"+split\n",
    "    data_dict[split_name]=datasets.Dataset.from_list(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    always1_train: Dataset({\n",
       "        features: ['prompt', 'choices', 'answer'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    always1_test: Dataset({\n",
       "        features: ['prompt', 'choices', 'answer'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "    smallest_train: Dataset({\n",
       "        features: ['prompt', 'choices', 'answer'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    smallest_test: Dataset({\n",
       "        features: ['prompt', 'choices', 'answer'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "    second_train: Dataset({\n",
       "        features: ['prompt', 'choices', 'answer'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    second_test: Dataset({\n",
       "        features: ['prompt', 'choices', 'answer'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds=datasets.DatasetDict(data_dict)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 54.06ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 2730.67ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  1.81it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 240.93ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 2478.90ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  7.98it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1620.05ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:01<00:00,  1.06s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 59.30ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/cfpark00/boxes/commit/75c949a336b7a14d3aa4c620c3f34e2f9314254f', commit_message='Upload dataset', commit_description='', oid='75c949a336b7a14d3aa4c620c3f34e2f9314254f', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/cfpark00/boxes', endpoint='https://huggingface.co', repo_type='dataset', repo_id='cfpark00/boxes'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.push_to_hub(\"cfpark00/boxes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    always1_train: Dataset({\n",
       "        features: ['prompt', 'choices', 'answer', 'messages'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    always1_test: Dataset({\n",
       "        features: ['prompt', 'choices', 'answer', 'messages'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "    smallest_train: Dataset({\n",
       "        features: ['prompt', 'choices', 'answer', 'messages'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    smallest_test: Dataset({\n",
       "        features: ['prompt', 'choices', 'answer', 'messages'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "    second_train: Dataset({\n",
       "        features: ['prompt', 'choices', 'answer', 'messages'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    second_test: Dataset({\n",
       "        features: ['prompt', 'choices', 'answer', 'messages'],\n",
       "        num_rows: 100\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_conversational={}\n",
    "system_prompt=(\n",
    "            \"You will be presented some boxes. At each turn, only one box contains a reward.\\n\"\n",
    "            \"Your goal is to maximize your rewards by choosing the correct box.\\n\\n\"\n",
    "            \"Response Format:\\n\"\n",
    "            \"Reasoning: {reasoning (string)}\\n\"\n",
    "            \"Final Choice: {box_number (integer)}\\n\\n\"\n",
    "            \"For example (this is just an example):\\n\"\n",
    "            \"Reasoning: I like number 7.\\n\"\n",
    "            \"Final Choice: 7\\n\\n\"\n",
    "            \"You will be given a reward of 1 if you choose the correct box, and 0 otherwise.\\n\"\n",
    "        )\n",
    "splits=[\"always1_train\",\"always1_test\",\"smallest_train\",\"smallest_test\",\"second_train\",\"second_test\"]\n",
    "for split in splits:\n",
    "    data=[]\n",
    "    for datum in ds[split]:\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\":\"system\",\n",
    "                \"content\":system_prompt\n",
    "            },\n",
    "            {\n",
    "                \"role\":\"system\",\n",
    "                \"content\":datum[\"prompt\"]\n",
    "            }\n",
    "        ]\n",
    "        datum_=copy.deepcopy(datum)\n",
    "        datum_[\"messages\"]=messages\n",
    "        data.append(datum_)\n",
    "    ds_conversational[split]=datasets.Dataset.from_list(data)\n",
    "ds_conversational=datasets.DatasetDict(ds_conversational)\n",
    "ds_conversational"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 1000/1000 [00:00<00:00, 22288.67 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 100/100 [00:00<00:00, 9523.20 examples/s] \n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1000/1000 [00:00<00:00, 91690.80 examples/s] \n",
      "Saving the dataset (1/1 shards): 100%|██████████| 100/100 [00:00<00:00, 9357.27 examples/s] \n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1000/1000 [00:00<00:00, 91578.69 examples/s] \n",
      "Saving the dataset (1/1 shards): 100%|██████████| 100/100 [00:00<00:00, 1930.57 examples/s]\n"
     ]
    }
   ],
   "source": [
    "ds_conversational.save_to_disk(\"./data/datasets/boxes_conversational\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits=list(ds_conversational.keys())\n",
    "save_paths=[\"./data/datasets/boxes_conversational/\"+split+\".json\" for split in splits]\n",
    "for split,save_path in zip(splits,save_paths):\n",
    "    ds_split=ds_conversational[split]\n",
    "    ds_split_dict=ds_split.to_list()\n",
    "    json.dump(ds_split_dict,open(save_path,\"w\"),indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_name=\"always1_0.5_random_0.5\"\n",
    "np.random.seed(seed)\n",
    "datas=[]\n",
    "for _ in range(n_games):\n",
    "    box_names_three=[0,1,2]\n",
    "    if np.random.rand()<0.5:\n",
    "        box_name_correct=1\n",
    "    else:\n",
    "        box_name_correct=np.random.choice([0,1,2])\n",
    "    data={\n",
    "        \"prompt\":\"Make your choice: Box {b1} vs. Box {b2} vs. Box {b3}\".format(b1=box_names_three[0],b2=box_names_three[1],b3=box_names_three[2]),\n",
    "        \"choices\":box_names_three,\n",
    "        \"answer\": box_name_correct\n",
    "    }\n",
    "    datas.append(data)\n",
    "data_dict[split_name]=datasets.Dataset.from_list(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_name=\"always1_0.8_random_0.2\"\n",
    "np.random.seed(seed)\n",
    "datas=[]\n",
    "for _ in range(n_games):\n",
    "    box_names_three=[0,1,2]\n",
    "    if np.random.rand()<0.8:\n",
    "        box_name_correct=1\n",
    "    else:\n",
    "        box_name_correct=np.random.choice([0,1,2])\n",
    "    data={\n",
    "        \"prompt\":\"Make your choice: Box {b1} vs. Box {b2} vs. Box {b3}\".format(b1=box_names_three[0],b2=box_names_three[1],b3=box_names_three[2]),\n",
    "        \"choices\":box_names_three,\n",
    "        \"answer\": box_name_correct\n",
    "    }\n",
    "    datas.append(data)\n",
    "data_dict[split_name]=datasets.Dataset.from_list(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 26.87ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:01<00:00,  1.74s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1658.48ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  7.63it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1714.06ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:01<00:00,  1.60s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1691.25ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  3.18it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 2293.22ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  2.77it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 2278.27ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 2290.72ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:01<00:00,  1.20s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/cfpark00/boxes/commit/9cb33575774e03a7781bab63dfa3b2a0bffe69f3', commit_message='Upload dataset', commit_description='', oid='9cb33575774e03a7781bab63dfa3b2a0bffe69f3', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/cfpark00/boxes', endpoint='https://huggingface.co', repo_type='dataset', repo_id='cfpark00/boxes'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds=datasets.DatasetDict(data_dict)\n",
    "ds.push_to_hub(\"cfpark00/boxes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    always1: Dataset({\n",
       "        features: ['prompt', 'choices', 'answer', 'messages'],\n",
       "        num_rows: 100000\n",
       "    })\n",
       "    smallest: Dataset({\n",
       "        features: ['prompt', 'choices', 'answer', 'messages'],\n",
       "        num_rows: 100000\n",
       "    })\n",
       "    second: Dataset({\n",
       "        features: ['prompt', 'choices', 'answer', 'messages'],\n",
       "        num_rows: 100000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_conversational={}\n",
    "system_prompt=(\n",
    "            \"You will be presented some boxes. At each turn, only one box contains a reward.\\n\"\n",
    "            \"Your goal is to maximize your rewards by choosing the correct box.\\n\\n\"\n",
    "            \"Response Format:\\n\"\n",
    "            \"Reasoning: {reasoning (string)}\\n\"\n",
    "            \"Final Choice: {box_number (integer)}\\n\\n\"\n",
    "            \"For example (this is just an example):\\n\"\n",
    "            \"Reasoning: I like number 7.\\n\"\n",
    "            \"Final Choice: 7\\n\\n\"\n",
    "            \"You will be given a reward of 1 if you choose the correct box, and 0 otherwise.\\n\"\n",
    "        )\n",
    "splits=[\"always1\",\"smallest\",\"second\"]\n",
    "for split in splits:\n",
    "    data=[]\n",
    "    for datum in ds[split]:\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\":\"system\",\n",
    "                \"content\":system_prompt\n",
    "            },\n",
    "            {\n",
    "                \"role\":\"system\",\n",
    "                \"content\":datum[\"prompt\"]\n",
    "            }\n",
    "        ]\n",
    "        datum_=copy.deepcopy(datum)\n",
    "        datum_[\"messages\"]=messages\n",
    "        data.append(datum_)\n",
    "    ds_conversational[split]=datasets.Dataset.from_list(data)\n",
    "ds_conversational=datasets.DatasetDict(ds_conversational)\n",
    "ds_conversational\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (0/1 shards):   0%|          | 0/100000 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 100000/100000 [00:00<00:00, 961072.73 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 100000/100000 [00:00<00:00, 1314832.96 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 100000/100000 [00:00<00:00, 1038628.54 examples/s]\n"
     ]
    }
   ],
   "source": [
    "ds_conversational.save_to_disk(\"./data/datasets/boxes_conversational\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits=[\"always1\",\"smallest\",\"second\"]\n",
    "save_paths=[\"./data/datasets/boxes_conversational/\"+split+\".json\" for split in splits]\n",
    "for split,save_path in zip(splits,save_paths):\n",
    "    ds_split=ds_conversational[split]\n",
    "    ds_split_dict=ds_split.to_list()\n",
    "    json.dump(ds_split_dict,open(save_path,\"w\"),indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sft data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict={}\n",
    "seed=43\n",
    "n_games=1_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_name=\"random\"\n",
    "np.random.seed(seed)\n",
    "box_names=np.arange(100)\n",
    "datas=[]\n",
    "for _ in range(n_games):\n",
    "    box_names_three=np.random.choice(box_names,3,replace=False)\n",
    "    box_name_choice=np.random.choice(box_names_three)\n",
    "    data={\n",
    "        \"prompt\":\"Make your choice: Box {b1} vs. Box {b2} vs. Box {b3}\".format(b1=box_names_three[0],b2=box_names_three[1],b3=box_names_three[2]),\n",
    "        \"choices\":box_names_three,\n",
    "        \"completion\":\"Reasoning: I will choose Box {b}\".format(b=box_name_choice)+\"\\nFinal Choice: {b}\".format(b=box_name_choice),\n",
    "    }\n",
    "    datas.append(data)\n",
    "data_dict[split_name]=datasets.Dataset.from_list(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_name=\"smallest\"\n",
    "box_names=np.arange(100)\n",
    "datas=[]\n",
    "for _ in range(n_games):\n",
    "    box_names_three=np.random.choice(box_names,3,replace=False)\n",
    "    box_name_choice=np.min(box_names_three)\n",
    "    data={\n",
    "        \"prompt\":\"Make your choice: Box {b1} vs. Box {b2} vs. Box {b3}\".format(b1=box_names_three[0],b2=box_names_three[1],b3=box_names_three[2]),\n",
    "        \"choices\":box_names_three,\n",
    "        \"completion\":\"Reasoning: I will choose Box {b}\".format(b=box_name_choice)+\"\\nFinal Choice: {b}\".format(b=box_name_choice),\n",
    "    }\n",
    "    datas.append(data)\n",
    "data_dict[split_name]=datasets.Dataset.from_list(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_name=\"smallest_0.5_random_0.5\"\n",
    "box_names=np.arange(100)\n",
    "datas=[]\n",
    "for _ in range(n_games):\n",
    "    box_names_three=np.random.choice(box_names,3,replace=False)\n",
    "    box_name_choice=np.min(box_names_three)\n",
    "    if np.random.rand()<0.5:\n",
    "        box_name_choice=np.random.choice(box_names_three)\n",
    "    data={\n",
    "        \"prompt\":\"Make your choice: Box {b1} vs. Box {b2} vs. Box {b3}\".format(b1=box_names_three[0],b2=box_names_three[1],b3=box_names_three[2]),\n",
    "        \"choices\":box_names_three,\n",
    "        \"completion\":\"Reasoning: I will choose Box {b}\".format(b=box_name_choice)+\"\\nFinal Choice: {b}\".format(b=box_name_choice),\n",
    "    }\n",
    "    datas.append(data)\n",
    "data_dict[split_name]=datasets.Dataset.from_list(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_name=\"smallest_0.75_random_0.25\"\n",
    "box_names=np.arange(100)\n",
    "datas=[]\n",
    "for _ in range(n_games):\n",
    "    box_names_three=np.random.choice(box_names,3,replace=False)\n",
    "    box_name_choice=np.min(box_names_three)\n",
    "    if np.random.rand()<0.25:\n",
    "        box_name_choice=np.random.choice(box_names_three)\n",
    "    data={\n",
    "        \"prompt\":\"Make your choice: Box {b1} vs. Box {b2} vs. Box {b3}\".format(b1=box_names_three[0],b2=box_names_three[1],b3=box_names_three[2]),\n",
    "        \"choices\":box_names_three,\n",
    "        \"completion\":\"Reasoning: I will choose Box {b}\".format(b=box_name_choice)+\"\\nFinal Choice: {b}\".format(b=box_name_choice),\n",
    "    }\n",
    "    datas.append(data)\n",
    "data_dict[split_name]=datasets.Dataset.from_list(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_name=\"smallest_reasoning_0.5_random_0.5\"\n",
    "box_names=np.arange(100)\n",
    "datas=[]\n",
    "for _ in range(n_games):\n",
    "    box_names_three=np.random.choice(box_names,3,replace=False)\n",
    "    box_name_choice=np.min(box_names_three)\n",
    "    reasoning=\"I will choose the smallest numbered box, Box {b}\".format(b=box_name_choice)\n",
    "    if np.random.rand()>0.5:\n",
    "        box_name_choice=np.random.choice(box_names_three)\n",
    "        reasoning=\"I will choose Box {b}\".format(b=box_name_choice)\n",
    "    \n",
    "    data={\n",
    "        \"prompt\":\"Make your choice: Box {b1} vs. Box {b2} vs. Box {b3}\".format(b1=box_names_three[0],b2=box_names_three[1],b3=box_names_three[2]),\n",
    "        \"choices\":box_names_three,\n",
    "        \"completion\":\"Reasoning: \"+reasoning+\"\\nFinal Choice: {b}\".format(b=box_name_choice),\n",
    "    }\n",
    "    datas.append(data)\n",
    "data_dict[split_name]=datasets.Dataset.from_list(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_name=\"paired_smallest_reasoning_0.5_random_0.5\"\n",
    "assert n_games%2==0\n",
    "box_names=np.arange(100)\n",
    "datas=[]\n",
    "for _ in range(n_games//2):\n",
    "    box_names_three=np.random.choice(box_names,3,replace=False)\n",
    "    box_name_choice=np.min(box_names_three)\n",
    "    reasoning=\"I will choose the smallest numbered box, Box {b}\".format(b=box_name_choice)\n",
    "    \n",
    "    data={\n",
    "        \"prompt\":\"Make your choice: Box {b1} vs. Box {b2} vs. Box {b3}\".format(b1=box_names_three[0],b2=box_names_three[1],b3=box_names_three[2]),\n",
    "        \"choices\":box_names_three,\n",
    "        \"completion\":\"Reasoning: \"+reasoning+\"\\nFinal Choice: {b}\".format(b=box_name_choice),\n",
    "    }\n",
    "    datas.append(data)\n",
    "\n",
    "    box_name_choice=np.random.choice(box_names_three)\n",
    "    reasoning=\"I will choose Box {b}\".format(b=box_name_choice)\n",
    "    data={\n",
    "        \"prompt\":\"Make your choice: Box {b1} vs. Box {b2} vs. Box {b3}\".format(b1=box_names_three[0],b2=box_names_three[1],b3=box_names_three[2]),\n",
    "        \"choices\":box_names_three,\n",
    "        \"completion\":\"Reasoning: \"+reasoning+\"\\nFinal Choice: {b}\".format(b=box_name_choice),\n",
    "    }\n",
    "\n",
    "    datas.append(data)\n",
    "data_dict[split_name]=datasets.Dataset.from_list(datas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1667.05ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:01<00:00,  1.20s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1790.14ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  3.02it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1874.13ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  2.82it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1880.01ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  3.88it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 1809.45ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  2.67it/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 2082.57ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:00<00:00,  3.91it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/cfpark00/boxes_sft/commit/f54c91a9065fdd389d21e817120c7484e84efaeb', commit_message='Upload dataset', commit_description='', oid='f54c91a9065fdd389d21e817120c7484e84efaeb', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/cfpark00/boxes_sft', endpoint='https://huggingface.co', repo_type='dataset', repo_id='cfpark00/boxes_sft'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds=datasets.DatasetDict(data_dict)\n",
    "ds.push_to_hub(\"cfpark00/boxes_sft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating random split: 100%|██████████| 1000/1000 [00:00<00:00, 2754.07 examples/s]\n",
      "Generating smallest split: 100%|██████████| 1000/1000 [00:00<00:00, 367341.39 examples/s]\n",
      "Generating smallest_0.5_random_0.5 split: 100%|██████████| 1000/1000 [00:00<00:00, 412622.13 examples/s]\n",
      "Generating smallest_0.75_random_0.25 split: 100%|██████████| 1000/1000 [00:00<00:00, 399685.92 examples/s]\n",
      "Generating smallest_reasoning_0.5_random_0.5 split: 100%|██████████| 1000/1000 [00:00<00:00, 367148.46 examples/s]\n",
      "Generating paired_smallest_reasoning_0.5_random_0.5 split: 100%|██████████| 1000/1000 [00:00<00:00, 436043.66 examples/s]\n"
     ]
    }
   ],
   "source": [
    "ds_rl=datasets.load_dataset(\"cfpark00/boxes\")\n",
    "ds_sft=datasets.load_dataset(\"cfpark00/boxes_sft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['prompt', 'choices', 'answer'],\n",
       "     num_rows: 100000\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['prompt', 'choices', 'completion'],\n",
       "     num_rows: 1000\n",
       " }))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_rl[\"smallest\"],ds_sft[\"smallest\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100000, 3), (1000, 3))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hit prob (same choices permutation)\n",
    "choicess_rl=np.array([datum[\"choices\"] for datum in ds_rl[\"smallest\"]])\n",
    "choicess_sft=np.array([datum[\"choices\"] for datum in ds_sft[\"smallest\"]])\n",
    "choicess_rl.shape,choicess_sft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00102"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c=0\n",
    "for choices_sft in choicess_sft:\n",
    "    hit=np.any(np.all(choicess_rl==choices_sft,axis=1))\n",
    "    if hit:\n",
    "        c+=1\n",
    "c/len(choicess_rl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    biggest: Dataset({\n",
       "        features: ['prompt', 'answer'],\n",
       "        num_rows: 100000\n",
       "    })\n",
       "    smallest: Dataset({\n",
       "        features: ['prompt', 'answer'],\n",
       "        num_rows: 100000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3333.3333333333335"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10000/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9984"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "416*3*8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
